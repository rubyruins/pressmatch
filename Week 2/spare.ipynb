{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, coming to Week 2 task. For each of the authors, you ideally want to know more about their background, topics of interest, twitter links etc.\n",
    "\n",
    "One easy way to grab it is going their muckrack journalist profile page and web scrapping it from there (refer to chapter 2, beautifulsoup portion to know how to do it).\n",
    "\n",
    "Two ways to do it: first, you can search through the muckrack sitemap CSV file for near duplicate matches in similar or same names and scrape their profiles. \n",
    "\n",
    "Second method is letting Bing/Google do the job aka take the author name and outlet name and search Google programmatically using Specrom APIs. For example if you want to know more about Dave Sebastian WSJ.com just use it as a search key and find muckrack profile and proceed from there. \n",
    "\n",
    "How about you trying doing do both approaches on top 10-30 authors and see which one works best?\n",
    "\n",
    "https://algorithmia.com/algorithms/specrom/Google_scraper\n",
    "\n",
    "https://algorithmia.com/algorithms/specrom/Bing_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import Algorithmia\n",
    "import bs4 as bs\n",
    "import lxml\n",
    "from urllib.request import Request, urlopen\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news.pkl', 'rb') as f:\n",
    "    news = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>site_name</th>\n",
       "      <th>title</th>\n",
       "      <th>article_count</th>\n",
       "      <th>title_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aja Styles</td>\n",
       "      <td>Brisbane Times</td>\n",
       "      <td>'Pack Lego': Perth family caught in hard borde...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>-9.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jake Johnson</td>\n",
       "      <td>Truthout</td>\n",
       "      <td>Congress Passes COVID Relief With Billions in ...</td>\n",
       "      <td>33.0</td>\n",
       "      <td>18.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Christine Favocci</td>\n",
       "      <td>The Western Journal</td>\n",
       "      <td>PA Man Facing Charges of Unlawful Voting After...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-38.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>William Rivers Pitt</td>\n",
       "      <td>Truthout</td>\n",
       "      <td>What Will Trump Attempt in His Last Days? We M...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Goodman</td>\n",
       "      <td>Truthout</td>\n",
       "      <td>The Insufficient COVID Stimulus Must Not Be Fo...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-20.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121126</th>\n",
       "      <td>Simon Bajkowski</td>\n",
       "      <td>Manchester Evening News</td>\n",
       "      <td>How Man City should line up vs Fulham in the P...</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121127</th>\n",
       "      <td>Victoria Jones</td>\n",
       "      <td>WalesOnline</td>\n",
       "      <td>How to teach saving and spending to kids as yo...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121128</th>\n",
       "      <td>Victoria Jones</td>\n",
       "      <td>WalesOnline</td>\n",
       "      <td>Space experiment could unlock resources for mi...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121129</th>\n",
       "      <td>Nisha Mal</td>\n",
       "      <td>WalesOnline</td>\n",
       "      <td>Woman's home is in Tier 2 while her garden fal...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121130</th>\n",
       "      <td>Victoria Jones</td>\n",
       "      <td>WalesOnline</td>\n",
       "      <td>Britannia ranked the UK's worst hotel chain fo...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-17.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121131 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     author                site_name  \\\n",
       "0                Aja Styles           Brisbane Times   \n",
       "1              Jake Johnson                 Truthout   \n",
       "2         Christine Favocci      The Western Journal   \n",
       "3       William Rivers Pitt                 Truthout   \n",
       "4               Amy Goodman                 Truthout   \n",
       "...                     ...                      ...   \n",
       "121126      Simon Bajkowski  Manchester Evening News   \n",
       "121127       Victoria Jones              WalesOnline   \n",
       "121128       Victoria Jones              WalesOnline   \n",
       "121129            Nisha Mal              WalesOnline   \n",
       "121130       Victoria Jones              WalesOnline   \n",
       "\n",
       "                                                    title  article_count  \\\n",
       "0       'Pack Lego': Perth family caught in hard borde...           14.0   \n",
       "1       Congress Passes COVID Relief With Billions in ...           33.0   \n",
       "2       PA Man Facing Charges of Unlawful Voting After...           19.0   \n",
       "3       What Will Trump Attempt in His Last Days? We M...           14.0   \n",
       "4       The Insufficient COVID Stimulus Must Not Be Fo...           19.0   \n",
       "...                                                   ...            ...   \n",
       "121126  How Man City should line up vs Fulham in the P...           87.0   \n",
       "121127  How to teach saving and spending to kids as yo...           92.0   \n",
       "121128  Space experiment could unlock resources for mi...           92.0   \n",
       "121129  Woman's home is in Tier 2 while her garden fal...           66.0   \n",
       "121130  Britannia ranked the UK's worst hotel chain fo...           92.0   \n",
       "\n",
       "        title_sentiment  \n",
       "0                 -9.09  \n",
       "1                 18.18  \n",
       "2                -38.46  \n",
       "3                  0.00  \n",
       "4                -20.00  \n",
       "...                 ...  \n",
       "121126             0.00  \n",
       "121127             0.00  \n",
       "121128             0.00  \n",
       "121129           -10.00  \n",
       "121130           -17.65  \n",
       "\n",
       "[121131 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fsfsgsfWRIULIP-9--\n"
     ]
    }
   ],
   "source": [
    "s = 'fsfsgsfWR#^^$&%*^IULIP(_-9--))'\n",
    "punctuations = '''!()[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "for x in s.lower(): \n",
    "        if x in punctuations: s = s.replace(x, \"\") \n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = news.copy()\n",
    "data = data[['author', 'article_count']].groupby('author').count().sort_values(['article_count'], ascending = False).reset_index()\n",
    "columns = ['verified', 'interests', 'title', 'location', 'description', \n",
    "           'seen_in', 'website', 'twitter', 'linkedin', 'facebook', 'instagram']\n",
    "for col in columns:\n",
    "    data[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>article_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>interests</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>seen_in</th>\n",
       "      <th>website</th>\n",
       "      <th>twitter</th>\n",
       "      <th>linkedin</th>\n",
       "      <th>facebook</th>\n",
       "      <th>instagram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neil Shaw</td>\n",
       "      <td>523</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Rodger</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Davis</td>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Wells</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie McCoid</td>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>Emma Dunkley</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3887</th>\n",
       "      <td>Tanya Jefferies</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>Liam Kelly</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>Levi Sumagaysay</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3890</th>\n",
       "      <td>Roshni Balaji</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3891 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  article_count  verified  interests  title  location  \\\n",
       "0           Neil Shaw            523         0          0      0         0   \n",
       "1        James Rodger            512         0          0      0         0   \n",
       "2          Jack Davis            251         0          0      0         0   \n",
       "3          Adam Wells            223         0          0      0         0   \n",
       "4       Sophie McCoid            218         0          0      0         0   \n",
       "...               ...            ...       ...        ...    ...       ...   \n",
       "3886     Emma Dunkley             10         0          0      0         0   \n",
       "3887  Tanya Jefferies             10         0          0      0         0   \n",
       "3888       Liam Kelly             10         0          0      0         0   \n",
       "3889  Levi Sumagaysay             10         0          0      0         0   \n",
       "3890    Roshni Balaji             10         0          0      0         0   \n",
       "\n",
       "      description  seen_in  website  twitter  linkedin  facebook  instagram  \n",
       "0               0        0        0        0         0         0          0  \n",
       "1               0        0        0        0         0         0          0  \n",
       "2               0        0        0        0         0         0          0  \n",
       "3               0        0        0        0         0         0          0  \n",
       "4               0        0        0        0         0         0          0  \n",
       "...           ...      ...      ...      ...       ...       ...        ...  \n",
       "3886            0        0        0        0         0         0          0  \n",
       "3887            0        0        0        0         0         0          0  \n",
       "3888            0        0        0        0         0         0          0  \n",
       "3889            0        0        0        0         0         0          0  \n",
       "3890            0        0        0        0         0         0          0  \n",
       "\n",
       "[3891 rows x 13 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>article_count</th>\n",
       "      <th>Muckrack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neil Shaw</td>\n",
       "      <td>523</td>\n",
       "      <td>https://muckrack.com/w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Rodger</td>\n",
       "      <td>512</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jack Davis</td>\n",
       "      <td>251</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adam Wells</td>\n",
       "      <td>223</td>\n",
       "      <td>https://muckrack.com/w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sophie McCoid</td>\n",
       "      <td>218</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>Luke Kenton</td>\n",
       "      <td>77</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Peter Sblendorio</td>\n",
       "      <td>77</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Emily Hodgkin</td>\n",
       "      <td>77</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>Tom Towers</td>\n",
       "      <td>76</td>\n",
       "      <td>https://muckrack.com/w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>Tom Davidson</td>\n",
       "      <td>76</td>\n",
       "      <td>https://muckrack.com/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author  article_count                Muckrack\n",
       "0           Neil Shaw            523  https://muckrack.com/w\n",
       "1        James Rodger            512   https://muckrack.com/\n",
       "2          Jack Davis            251   https://muckrack.com/\n",
       "3          Adam Wells            223  https://muckrack.com/w\n",
       "4       Sophie McCoid            218   https://muckrack.com/\n",
       "..                ...            ...                     ...\n",
       "295       Luke Kenton             77   https://muckrack.com/\n",
       "296  Peter Sblendorio             77   https://muckrack.com/\n",
       "297     Emily Hodgkin             77   https://muckrack.com/\n",
       "298        Tom Towers             76  https://muckrack.com/w\n",
       "299      Tom Davidson             76   https://muckrack.com/\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_top(n):\n",
    "    temp = news[['author', 'article_count']].groupby('author').count().sort_values(['article_count'], ascending = False)\n",
    "    temp = temp.reset_index().head(n)\n",
    "    urls = []\n",
    "    for i in range(len(temp)):\n",
    "        url = re.sub(r'(\\w*.\\w*@\\w*.\\w*)', '', temp.loc[i].author.lower()) # remove emails\n",
    "        url = re.sub(r'\\|.*$', '', url) # remove everything after |\n",
    "        url = re.sub(r'\\,.*$', '', url) # remove evrything after ,\n",
    "        url = re.sub(r'[^\\\\w-]', '', url) # remove punctuation\n",
    "        url = ' '.join([i.strip() for i in url.split()]) # remove spaces and lowercase\n",
    "        url = re.sub(r'(sa)(\\s+)(\\w+)(\\s+)', '', url) # SA editors\n",
    "        url = re.sub(r'(tulsa)(\\s+)(world)', '', url) # tulsa world editors\n",
    "        url = re.sub(r'(\\d+)', '', url) # remove numbers\n",
    "        url = 'https://muckrack.com/' + url.replace(' ', '-').strip('-') # make URL\n",
    "        # print(muckrack[muckrack.url.str.contains(url, regex=False)])\n",
    "        urls.append(url)\n",
    "    temp['Muckrack'] = urls\n",
    "    return temp\n",
    "\n",
    "get_top(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Algorithmia.algorithm.Algorithm at 0x12024982e88>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Algorithmia.client('simKLMHlWDMzWd+QcNRqVhI104r1')\n",
    "algo = client.algo('specrom/Google_scraper/0.1.4')\n",
    "algo.set_options(timeout=300) # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_top(3891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrong url https://muckrack.com/matthew-cooper Matthew Cooper\n",
      "wrong url https://muckrack.com/svar-nanansen Svar Nanan-Sen\n",
      "wrong url https://muckrack.com/seamus-duff Seamus Duff\n",
      "wrong url https://muckrack.com/alessandra-scotto-di-santolo Alessandra Scotto di Santolo\n",
      "wrong url https://muckrack.com/ryan-taylor Ryan Taylor\n",
      "wrong url https://muckrack.com/beth-mishlerelmore Beth Mishler-Elmore\n",
      "wrong url https://muckrack.com/liam-doyle Liam Doyle\n",
      "wrong url https://muckrack.com/jessica-dolcourt Jessica Dolcourt\n",
      "wrong url https://muckrack.com/unzela-khan Unzela Khan\n",
      "wrong url https://muckrack.com/elle-may-rice Elle May Rice\n",
      "wrong url https://muckrack.com/austin-boyd Austin Boyd\n",
      "wrong url https://muckrack.com/molly-pike Molly Pike\n",
      "wrong url https://muckrack.com/bryony-jewell Bryony Jewell\n",
      "wrong url https://muckrack.com/lucas-hillpaul Lucas Hill-Paul\n",
      "wrong url https://muckrack.com/saraaisha-kent Sara-Aisha Kent\n",
      "wrong url https://muckrack.com/charlie-spiering Charlie Spiering\n",
      "wrong url https://muckrack.com/ira-winderman Ira Winderman\n",
      "wrong url https://muckrack.com/connor-coombewhitlock Connor Coombe-Whitlock\n",
      "wrong url https://muckrack.com/muri-assunção Muri Assunção\n",
      "wrong url https://muckrack.com/paul-withers Paul Withers\n",
      "wrong url https://muckrack.com/andy-meek Andy Meek\n",
      "wrong url https://muckrack.com/helen-carter Helen Carter\n",
      "wrong url https://muckrack.com/kellyann-mills Kelly-Ann Mills\n",
      "wrong url https://muckrack.com/luke-traynor Luke Traynor\n",
      "wrong url https://muckrack.com/dinoray-ramos Dino-Ray Ramos\n",
      "wrong url https://muckrack.com/jon-blistein Jon Blistein\n",
      "wrong url https://muckrack.com/jacob-siegal Jacob Siegal\n",
      "wrong url https://muckrack.com/sam-mckewon-worldherald-staff-writer Sam McKewon World-Herald staff writer\n",
      "wrong url https://muckrack.com/japan-today Japan Today\n",
      "wrong url https://muckrack.com/dave-mcnary Dave McNary\n",
      "wrong url https://muckrack.com/torcuil-crichton Torcuil Crichton\n",
      "wrong url https://muckrack.com/chloelee-longhetti Chloe-lee Longhetti\n",
      "wrong url https://muckrack.com/mary-kekatos-senior Mary Kekatos Senior\n",
      "wrong url https://muckrack.com/keith-pompey Keith Pompey\n",
      "wrong url https://muckrack.com/danny-cyril-d-cruze Danny Cyril D Cruze\n",
      "wrong url https://muckrack.com/vinny-somma Vinny Somma\n",
      "wrong url https://muckrack.com/evan-bland-worldherald-staff-writer Evan Bland World-Herald staff writer\n",
      "wrong url https://muckrack.com/stephen-mosher Stephen Mosher\n",
      "wrong url https://muckrack.com/broganleigh-hurst Brogan-Leigh Hurst\n",
      "wrong url https://muckrack.com/brandwagon-online BrandWagon Online\n",
      "wrong url https://muckrack.com/levi-parsons Levi Parsons\n",
      "wrong url https://muckrack.com/claire-gilbodydickerson Claire Gilbody-Dickerson\n",
      "wrong url https://muckrack.com/paul-hutcheon Paul Hutcheon\n",
      "wrong url https://muckrack.com/chris-basnett Chris  Basnett\n",
      "wrong url https://muckrack.com/goh-yan-han GOH YAN HAN\n",
      "wrong url https://muckrack.com/daniel-kreps Daniel Kreps\n",
      "wrong url https://muckrack.com/bridie-pearsonjones Bridie Pearson-jones\n",
      "wrong url https://muckrack.com/charlie-coë Charlie Coë\n",
      "wrong url https://muckrack.com/jason-cipriani Jason Cipriani\n",
      "wrong url https://muckrack.com/amy-graff Amy Graff, SFGATE\n",
      "wrong url https://muckrack.com/johnpaul-clark John-Paul Clark\n",
      "wrong url https://muckrack.com/ana-suarez Ana Suarez\n",
      "wrong url https://muckrack.com/amanda-thomason Amanda Thomason\n",
      "wrong url https://muckrack.com/omar-kelly Omar Kelly\n",
      "wrong url https://muckrack.com/sean-murphy Sean Murphy\n",
      "wrong url https://muckrack.com/ben-turnerle Ben Turner-LE\n",
      "wrong url https://muckrack.com/sophie-hallerichards Sophie Halle-Richards\n",
      "wrong url https://muckrack.com/joshua-caplan Joshua Caplan\n",
      "wrong url https://muckrack.com/rory-tingle Rory Tingle\n",
      "wrong url https://muckrack.com/dr-susan-berry Dr. Susan Berry\n",
      "wrong url https://muckrack.com/matt-murschel Matt Murschel\n",
      "wrong url https://muckrack.com/amanda-kooser Amanda Kooser\n",
      "wrong url https://muckrack.com/pangchieh @pang-chieh\n",
      "wrong url https://muckrack.com/condé-nast Condé Nast\n",
      "wrong url https://muckrack.com/gráinne-ní-aodha Gráinne Ní Aodha\n",
      "wrong url https://muckrack.com/stephen-rex-brown Stephen Rex Brown\n",
      "wrong url https://muckrack.com/christy-wheeland-news-editor Christy Wheeland News Editor\n",
      "wrong url https://muckrack.com/john-oconnor-richmond-timesdispatch JOHN O'CONNOR Richmond Times-Dispatch\n",
      "wrong url https://muckrack.com/shawn-hein-staff-writer Shawn Hein Staff Writer\n",
      "wrong url https://muckrack.com/jon-nyatawa-worldherald-staff-writer Jon Nyatawa World-Herald staff writer\n",
      "wrong url https://muckrack.com/paul-feely-new-hampshire-union-leader Paul Feely New Hampshire Union Leader\n",
      "wrong url https://muckrack.com/rónán-duffy Rónán Duffy\n",
      "wrong url https://muckrack.com/gen-alpha Gen Alpha\n",
      "wrong url https://muckrack.com/jason-wilde-for-the-state-journal JASON WILDE For the State Journal\n",
      "wrong url https://muckrack.com/lim-ruey-yan LIM RUEY YAN\n",
      "wrong url https://muckrack.com/joe-otterson Joe Otterson\n",
      "wrong url https://muckrack.com/keith-groller Keith Groller\n",
      "wrong url https://muckrack.com/landon Landon Stamper lstamper@aikenstandard.com\n",
      "wrong url https://muckrack.com/chicago-tribune-staff Chicago Tribune staff\n",
      "wrong url https://muckrack.com/richard-davenport Richard Davenport\n",
      "wrong url https://muckrack.com/ellie-kirwinjones Ellie Kirwin-Jones\n",
      "wrong url https://muckrack.com/howard-fischer-capitol-media-services Howard Fischer Capitol Media Services\n",
      "wrong url https://muckrack.com/scott-bauer SCOTT BAUER\n",
      "wrong url https://muckrack.com/field-level-media Field Level Media\n",
      "wrong url https://muckrack.com/jason-evans Jason Evans\n",
      "wrong url https://muckrack.com/cónal-thomas Cónal Thomas\n",
      "wrong url https://muckrack.com/greg-beacham GREG BEACHAM\n",
      "wrong url https://muckrack.com/sarah-alarshani Sarah Al-Arshani\n",
      "wrong url https://muckrack.com/steve-neville Steve Neville\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(data)):\n",
    "    try:\n",
    "        url = data.iloc[j].Muckrack\n",
    "        req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "        sauce = urlopen(req).read()\n",
    "    except:\n",
    "        print(\"wrong url\", data.iloc[j].Muckrack, data.iloc[j].author)\n",
    "        query = {\"query\": f\"{data.iloc[j].author} site: muckrack\"}\n",
    "        url = algo.pipe(query).result\n",
    "        if url:\n",
    "            url = url[0]['url']\n",
    "            print(\"right url\", url)\n",
    "            print()\n",
    "            req = Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            sauce = urlopen(req).read()\n",
    "    soup = bs.BeautifulSoup(sauce,'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(link):\n",
    "    info = {}\n",
    "    info['name'] = data.iloc[j].author\n",
    "    if soup.find_all(class_ = 'profile-verified'):\n",
    "        info['verified'] = True\n",
    "    if soup.find(class_ = 'person-details-item person-details-beats'):\n",
    "        info['interests'] = ' '.join([line.strip() for line in soup.find(class_ = 'fa fa-fw fa-tasks icon-standard').findNext('div').text.split('\\n') if line.strip() != ''])\n",
    "    if soup.find(class_ = 'person-details-item person-details-title'):\n",
    "        info['title'] = ' '.join([line.strip() for line in soup.find(class_ = 'fa fa-fw fa-building icon-standard').findNext('div').text.split('\\n') if line.strip() != ''])\n",
    "    if soup.find(class_ = 'person-details-item person-details-location'):\n",
    "        info['location'] = ' '.join([line.strip() for line in soup.find(class_ = 'fa fa-fw fa-map-marker icon-standard').findNext('div').text.split('\\n') if line.strip() != ''])\n",
    "    if soup.find(class_ = 'mr-font-size-lg mr-font-family-2 top-sm'):\n",
    "        info['description'] = soup.find(class_ = 'mr-font-size-lg mr-font-family-2 top-sm').text.strip()\n",
    "    info['seen_in'] = list(set([i.text for i in soup.find_all('a') if '/media-outlet/' in i.attrs['href']]))\n",
    "    if soup.find(class_ = 'profile-section-social'):\n",
    "        for i in soup.find(class_ = 'profile-section-social'):\n",
    "            temp = [j[5:] for j in str(i).split() if 'href' in j]\n",
    "            if temp: \n",
    "                temp = temp[0].strip('\"')\n",
    "                if 't.co' in temp:\n",
    "                    info['website'] = temp\n",
    "                if 'twitter' in temp:\n",
    "                    info['twitter'] = temp\n",
    "                if 'linkedin' in temp:\n",
    "                    info['linkedin'] = temp\n",
    "                if 'facebook' in temp:\n",
    "                    info['facebook'] = temp\n",
    "                if 'instagram' in temp:\n",
    "                    info['instagram'] = temp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
